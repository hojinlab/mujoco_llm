import threading
import json
import yaml
import os
import re
from queue import Queue
from dotenv import load_dotenv
import ollama
# from sympy.physics.units import temperature
# from tornado.options import options

#YOLO
from ultralytics import YOLO
import cv2

# from learn_LLM.yolo_GEMINI import question

load_dotenv()

TARGET_MAP = {
    "í•˜íŠ¸": "heart",
    "heart": "heart",
    "ë‹¤ì´ì•„": "diamond",
    "ë‹¤ì´ì•„ëª¬ë“œ": "diamond",
    "diamond": "diamond",
    "í´ë¡œë²„": "club",
    "í´ë¡œë°”": "club",
    "í´ëŸ½": "club",
    "club": "club",
    "ìŠ¤í˜ì´ë“œ": "spade",
    "spade": "spade",
}

SEARCH_CMD = {
    "heart": "SEARCH_HEART",
    "diamond": "SEARCH_DIAMOND",
    "club": "SEARCH_CLUB",
    "spade": "SEARCH_SPADE",
}

# ============================================
# OLLAMA LLM RUNNER FOR TURTLEBOT3
# ============================================

class OllamaTb3:
    def __init__(self, prompt_path, model=None, command_queue=None):
        self.command_queue = command_queue if command_queue else Queue()

        # Load prompt.yaml
        with open(prompt_path, "r", encoding="utf-8") as f:
            self.system_instruction = yaml.safe_load(f)["template"]

        self.client = ollama.Client(host=os.environ["OLLAMA_HOST"])
        self.model_name = model

        self.thread = None
        self.stop_event = threading.Event()

    # ----------------------------------------
    def run_ollama(self, question, detection_json):
        """Ollamaì—ê²Œ ë¶„ì„ ìš”ì²­"""
        print(f"[OllamaTb3] Using model: {self.model_name}")
        user_content = f"""
        # ê°ì§€ëœ ê°ì²´ ì •ë³´(JSON): {detection_json}
        
        # ì§ˆë¬¸: {question}
        """

        try:
            response = self.client.chat(
                model=self.model_name,
                messages=[
                    {'role': 'system', 'content': self.system_instruction},
                    {'role': 'user', 'content': user_content},
                ],
                options={'temperature': 0.1}
            )

            return response['message']['content']
        except Exception as e:
            return f"Ollama Error: {e}"
    # ----------------------------------------
    def _extract_target_from_question(self, q: str) -> str | None:
        q_low = q.lower()
        # ê¸´ ë‹¨ì–´ ìš°ì„ (ë‹¤ì´ì•„ëª¬ë“œê°€ ë‹¤ì´ì•„ë³´ë‹¤ ë¨¼ì € ë§¤ì¹­ë˜ê²Œ)
        keys = sorted(TARGET_MAP.keys(), key=len, reverse=True)
        for k in keys:
            if k.lower() in q_low:
                return TARGET_MAP[k]
        return None
    # ----------------------------------------
    def talk(self, sim):
        while not self.stop_event.is_set():
            try:
                question = input("\nğŸ’¬ Human: ")

                # YOLO
                det_dict = sim.yolo_detect_dict() or {}
                det_json = json.dumps(det_dict, ensure_ascii=False, indent=2)

                # ëª©í‘œ ì¹´ë“œ ì¶”ì¶œ (heart/diamond/club/spade)
                target = self._extract_target_from_question(question)

                # 1) ëª©í‘œê°€ ìˆëŠ”ë° í™”ë©´ì— ì—†ìœ¼ë©´: SEARCH ëª¨ë“œë¡œ ì „í™˜í•˜ê³  ì´ í„´ì€ ë
                if target and target not in det_dict:
                    cmd = SEARCH_CMD[target]
                    print(f"â¡ï¸ '{target}' ì¹´ë“œê°€ ì•ˆ ë³´ì—¬ì„œ {cmd}ë¡œ íƒìƒ‰í• ê²Œìš”.")
                    self.command_queue.put(cmd)

                    # ì—¬ê¸°ì„œ LLMì„ í˜¸ì¶œí•˜ë©´ "ë©ˆì¶¤" ê°™ì€ ì•¡ì…˜ì´ ë˜ ë“¤ì–´ì™€ì„œ ê²€ìƒ‰ì´ ëŠê¸¸ ìˆ˜ ìˆìŒ
                    # ë”°ë¼ì„œ ì´ í„´ì€ ì¢…ë£Œ(=ê²€ìƒ‰ë§Œ ìˆ˜í–‰)
                    continue

                # 2) ëª©í‘œê°€ ìˆê±°ë‚˜/ì—†ê±°ë‚˜ ìƒê´€ì—†ì´ LLM í˜¸ì¶œ (ë‹¨, ëª©í‘œê°€ ìˆë‹¤ë©´ ì´ë¯¸ ë³´ì´ëŠ” ìƒíƒœ)
                answer = self.run_ollama(question, det_json)
                print(f"\nğŸ¤– AI:\n{answer}\n")

                # 3) Action ì¶”ì¶œ
                action_match = re.search(r"Action:\s*([^\n]+)", answer)
                action = action_match.group(1).strip() if action_match else ""

                # 4) ë°©ì–´ ë¡œì§:
                # - ëª©í‘œê°€ ìˆê³  'ë³´ì´ëŠ”' ìƒíƒœì¸ë° LLMì´ ë©ˆì¶¤ì„ ë‚´ë©´, ì¼ë‹¨ ë©ˆì¶¤ë„ ì¡´ì¤‘í•˜ê±°ë‚˜
                #   ë„¤ê°€ ì›í•˜ë©´ "target ìª½ìœ¼ë¡œ ì´ë™" ê°™ì€ ë£°ì„ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŒ.
                if action:
                    print(f"â¡ï¸ Extracted Action: {action}")
                    self.command_queue.put(action)

            except EOFError:
                break
    # ----------------------------------------
    # Gemini + YOLO ìŠ¤ë ˆë“œ ì‹œì‘
    def start(self, sim):
        self.thread = threading.Thread(target=self.talk, args=(sim,), daemon=True)
        self.thread.start()