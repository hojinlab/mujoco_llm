{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjZ-4HVhT6M",
        "outputId": "0e519bc7-6850-4f8b-bd82-b7e23989d3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-ky3sxqiz/unsloth_2b01210ebfde4d908a7372116b302688\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-ky3sxqiz/unsloth_2b01210ebfde4d908a7372116b302688\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 8ea5338154859ed25b50366cb1264ed4d933eae3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth_zoo>=2025.12.7 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.12.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.3)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.3)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.3.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.49.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.0)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n",
            "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Using cached trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n",
            "Using cached trl-0.24.0-py3-none-any.whl (423 kB)\n",
            "Installing collected packages: trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.8.6\n",
            "    Uninstalling trl-0.8.6:\n",
            "      Successfully uninstalled trl-0.8.6\n",
            "Successfully installed trl-0.24.0\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.12/dist-packages (0.0.33.post2)\n",
            "Collecting trl<0.9.0\n",
            "  Using cached trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.0)\n",
            "Using cached trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "Installing collected packages: trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.24.0\n",
            "    Uninstalling trl-0.24.0:\n",
            "      Successfully uninstalled trl-0.24.0\n",
            "Successfully installed trl-0.8.6\n"
          ]
        }
      ],
      "source": [
        "# Unsloth ë° ì˜ì¡´ì„± ì„¤ì¹˜ (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦½ë‹ˆë‹¤)\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-M-y4Fbhunn",
        "outputId": "a8cfd99d-d82d-4fbd-a761-cda48fe21266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, TextStreamer\n",
        "from unsloth import is_bfloat16_supported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylbz-3dbNhHQ",
        "outputId": "0b95ac4e-9296-417e-dec6-daf2a14e4f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# Google Drive ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9e-h7XEQhsg0"
      },
      "outputs": [],
      "source": [
        "# ì„¤ì •\n",
        "model_name = \"unsloth/Qwen3-0.6B-unsloth-bnb-4bit\"\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEZbkqIah3V8",
        "outputId": "881e79c2-c995-4764-cbf7-7a0c167998d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘... (unsloth/Qwen3-0.6B-unsloth-bnb-4bit)\n",
            "==((====))==  Unsloth 2025.12.9: Fast Qwen3 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.12.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "print(f\" ëª¨ë¸ ë¡œë“œ ì¤‘... ({model_name})\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "\n",
        "# LoRA ì–´ëŒ‘í„° ì„¤ì •\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IFlfII8TSAl6"
      },
      "outputs": [],
      "source": [
        "# ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
        "system_prompt = \"ë‹¹ì‹ ì€ 6G ì´ë™í†µì‹ ê³¼ AI ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"\n",
        "question_text = \"6G ë„¤íŠ¸ì›Œí¬ì—ì„œ AIì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar4LiI9iin4a",
        "outputId": "b308f363-6781-4815-bfc4-3329000a8f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "ğŸ›‘ [Before] í•™ìŠµ ì „ ê¸°ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
            "==================================================\n",
            "<think>\n",
            "Okay, the user is asking about the role of AI in 6G networks. I need to explain it clearly in Korean. Let me start by recalling what I know. 6G is the next generation of wireless technology, so it's going to be much faster, more efficient, and have more capabilities. AI is going to play a big role here.\n",
            "\n",
            "First, I should mention how AI will optimize network performance. For example, using machine learning to predict and adapt to user behavior. That would make the network more responsive. Then, AI might help in resource allocation, like dynamically assigning bandwidth to different users. That would improve overall efficiency.\n",
            "\n",
            "I need to highlight how AI can enhance security and reliability. AI can detect anomalies and ensure data privacy. Also, AI might support advanced features like quantum computing, which could be integrated into 6G. But wait, the user might not know about quantum computing yet. So, I should mention that.\n",
            "\n",
            "Another point is how AI can make 6G more intelligent, such as through predictive maintenance and smart routing. This would lead to faster and more efficient communication. Also, AI could help in creating more secure and private networks, which is a big deal for future communication.\n",
            "\n",
            "I should make sure to structure the answer in a logical order: introduction, key points, and conclusion. Avoid technical jargon if possible, but keep it clear. Need to check if there are any recent developments in 6G and AI that I should reference. Maybe mention some examples like quantum computing or machine learning models.\n",
            "\n",
            "Wait, the user might be looking for a comprehensive answer that covers both technical aspects and potential future applications. I should ensure that each point is explained in a way that connects AI with 6G's goals, like speed, efficiency, and connectivity. Also, emphasize the benefits for users and the overall network experience.\n",
            "\n",
            "I think that's a solid approach. Now, put it all into Korean, making sure the language is clear and accurate.\n",
            "</think>\n",
            "\n",
            "6G ë„¤íŠ¸ì›Œí¬ì—ì„œ AIëŠ” ì „ ì„¸ê³„ì˜ ì „ë¬¸ì„±ì„ ë†€ë¼ê³ , ê¸°ìˆ ì  ì„±ëŠ¥ì„ ê°œì„ í•˜ë©° ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ëŠ” ì—­í• ì„ ë‹¬ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.  \n",
            "\n",
            "ì²«ì§¸, AIëŠ” 6Gì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ì „ëµì  ì „ëµì„ ìˆ˜ë¦½í•˜ê³ , ì‚¬ìš©ì í–‰ë™ì„ ì§„ì…í•˜ê³ , ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, AIê°€ í†µì‹  ì†ë„ë¥¼ ï¿½\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# í•™ìŠµ ì „(Before) ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" [Before] í•™ìŠµ ì „ ê¸°ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ì¶”ë¡  ëª¨ë“œ ì „í™˜\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# ë©”ì‹œì§€ êµ¬ì„± (System í”„ë¡¬í”„íŠ¸ ì¶”ê°€)\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": question_text + \" (í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜)\"}\n",
        "]\n",
        "\n",
        "# í† í°í™”\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# ë‹µë³€ ìƒì„±\n",
        "_ = model.generate(\n",
        "    input_ids = inputs,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True),\n",
        "    max_new_tokens = 512,\n",
        "    use_cache = True,\n",
        "    temperature = 0.7,\n",
        ")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0G75FQdh6BW",
        "outputId": "0d32f047-0e65-4508-8940-5d5692735b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! (ìƒ˜í”Œ): <|im_start|>user\n",
            "2025 6G White Paperì˜ ì£¼ìš” ì£¼ì œëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<think>\n",
            "\n",
            "</think...\n"
          ]
        }
      ],
      "source": [
        "# ë°ì´í„°ì…‹ ë¡œë“œ ë° í¬ë§·íŒ…\n",
        "dataset_file = \"/content/drive/MyDrive/js_mujoco/learn_LLM/src/6g_ai_dataset_augmented.jsonl\"\n",
        "\n",
        "if not os.path.exists(dataset_file):\n",
        "    raise FileNotFoundError(f\" ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_file}\\níŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=dataset_file, split=\"train\")\n",
        "\n",
        "# Qwen ì±„íŒ… í…œí”Œë¦¿ ì ìš©\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    outputs = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": instruction},\n",
        "            {\"role\": \"assistant\", \"content\": output}\n",
        "        ]\n",
        "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "\n",
        "train_dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "print(f\" ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! (ìƒ˜í”Œ): {train_dataset[0]['text'][:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "MP26r_DiiKVD",
        "outputId": "4a2c62f2-1eb5-4463-af21-0c32186c4b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 36 | Num Epochs = 12 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 10,092,544 of 606,142,464 (1.67% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 01:40, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.977800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.085300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>6.056000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>6.143400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>6.087500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>6.025000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‰ í•™ìŠµ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# í•™ìŠµ (Training)\n",
        "print(\" í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60, # ë°ì´í„° ì–‘ì— ë”°ë¼ ì¡°ì ˆ (60ì€ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì ì ˆ)\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # ì™„ë””ë¹„(wandb) ë„ê¸°\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()\n",
        "print(\" í•™ìŠµ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss49SQJWiQNP",
        "outputId": "12080cf3-0480-4eff-a79d-fdb72dc3b95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "âœ… [After] í•™ìŠµ í›„ íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ \n",
            "==================================================\n",
            "<think>\n",
            "Okay, the user is asking about the role of AI in 6G networks. I need to explain it in Korean. First, I should recall what 6G is. It's a future network, right? So the question is about how AI contributes to that.\n",
            "\n",
            "I should start by mentioning AI's main functions. Maybe things like data processing, optimization, and security. Then, I can talk about specific technologies like machine learning models, quantum computing, and edge computing. Also, AI helps in enhancing the network's performance, enabling better services, and improving security. Need to make sure it's clear and flows well in Korean. Check that the explanation covers the key points without being too technical, keeping it simple. Make sure the answer is concise and addresses the user's query.\n",
            "</think>\n",
            "\n",
            "6G ë„¤íŠ¸ì›Œí¬ì—ì„œ AIëŠ” ê¸°ì¡´ì˜ í†µì‹  ê¸°ìˆ ë³´ë‹¤ ë”ìš± ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³ , ì‹ ì†í•œ ëŒ€ì‘ê³¼ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. AI ê¸°ë°˜ì˜ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•, ìš´ì˜, ë³´í˜¸, ì„œë¹„ìŠ¤ ê°œì„ ì— ì¤‘ìš”í•œ ì—­í• ì„ í•˜ë©°, ë‹¤ìŒì˜ ì£¼ìš” ê¸°ëŠ¥ì„ í†µí•´ 6Gë¥¼ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
            "\n",
            "1. **ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„**: AIëŠ”æµ·é‡ ë°ì´í„°ë¥¼ ìµœì ì˜ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ì˜ˆì¸¡ ë° ì˜ˆì¸¡ ì§€ë„ë¥¼ í†µí•´ ì‹ ì†í•˜ê²Œ ì„œë¹„ìŠ¤ ì œê³µì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
            "2. **ìµœì ì˜ ì „ëµ êµ¬ì¶•**: AI ê¸°ë°˜ì˜ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ì „ëµì„ ìµœì í™”í•˜ê³ , ìš´ì˜ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
            "3. **ë³´ì•ˆ ë° ì•ˆì „ì„± ê°•í™”**: AI ê¸°ë°˜ì˜ ë³´í˜¸ ì•Œê³ ë¦¬ì¦˜ì€ ë°ì´í„° ì†ì‹¤ ë°©ì§€, ì•”í˜¸í™” ê¸°ìˆ ì„ í†µí•œ ë³´ì•ˆì„±ì„ ë†’ì´ê³ , 6Gì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.\n",
            "4. **ëœë„ ë° ë¹…ë°ì´í„° ë¶„ì„**: AIëŠ” ë¹…ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ë¶„ì„ì„ í†µí•´ ì„œë¹„ìŠ¤ í’ˆì§ˆì„ ê°œì„ í•˜ê³ , 6G ê¸°ìˆ ì˜ ë°œì „ì„ ì´‰ì§„í•©ë‹ˆë‹¤.\n",
            "\n",
            "AIëŠ” 6Gë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìµœì‹  ê¸°ìˆ ì˜ í˜ì‹ ì„ ì§€ì›í•˜ê³ , 6Gì˜ ì„±ê³µì ì¸ êµ¬í˜„ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.<|im_end|>\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ì¶”ë¡  í…ŒìŠ¤íŠ¸ (Inference)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" [After] í•™ìŠµ í›„ íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ \")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ì¶”ë¡  ëª¨ë“œ ì „í™˜ (í˜¹ì‹œ í•™ìŠµ ëª¨ë“œì˜€ë‹¤ë©´ ë‹¤ì‹œ ë³€ê²½)\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# ë©”ì‹œì§€ êµ¬ì„±\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": question_text + \" (í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜)\"}\n",
        "]\n",
        "\n",
        "# í† í°í™”\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# ë‹µë³€ ìƒì„±\n",
        "_ = model.generate(\n",
        "    input_ids = inputs,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True),\n",
        "    max_new_tokens = 512,\n",
        "    use_cache = True,\n",
        "    temperature = 0.7,\n",
        ")\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooq3WoHTiS3q",
        "outputId": "8ec3a8d4-1df3-45a0-8810-b3f02437db64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë¡œì»¬ ì €ì¥ ì™„ë£Œ: lora_model\n",
            "ğŸš€ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë°±ì—… ì™„ë£Œ: /content/drive/MyDrive/my_finetuned_qwen\n"
          ]
        }
      ],
      "source": [
        "# ë¨¼ì € ë¡œì»¬(Colab)ì— ëª¨ë¸ ì €ì¥\n",
        "model.save_pretrained(\"lora_model\")\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "print(\" ë¡œì»¬ ì €ì¥ ì™„ë£Œ: lora_model\")\n",
        "\n",
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œë¡œ ë³µì‚¬\n",
        "import shutil\n",
        "\n",
        "drive_path = \"/content/drive/MyDrive/my_finetuned_qwen\"\n",
        "\n",
        "if os.path.exists(\"lora_model\"):\n",
        "    shutil.copytree(\"lora_model\", drive_path, dirs_exist_ok=True)\n",
        "    print(f\" êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë°±ì—… ì™„ë£Œ: {drive_path}\")\n",
        "else:\n",
        "    print(\" ì—¬ì „íˆ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ ì €ì¥ ì½”ë“œê°€ ì œëŒ€ë¡œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-lR6FM3UGum"
      },
      "source": [
        "ëŸ°íƒ€ì„ ì„¸ì…˜ ë‹¤ì‹œ ì‹œì‘ í›„ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOCdWAgT9iu",
        "outputId": "426a8b5e-0109-459b-896b-13670a64e83d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤: /content/drive/MyDrive/my_finetuned_qwen\n",
            "==((====))==  Unsloth 2025.12.9: Fast Qwen3 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n",
            "\n",
            "<think>\n",
            "Okay, the user is asking about the role of AI in 6G networks. Let me start by recalling what I know. 6G is a future network concept, so it's going to be more advanced than current 5G. AI is a key component here, so I need to explain how AI can be used in 6G.\n",
            "\n",
            "First, I should mention the integration of AI with 6G. AI will play a critical role in processing and analyzing data, which is essential for 6G's capabilities. Then, maybe talk about applications like autonomous vehicles, smart cities, etc. It's important to highlight how AI will improve efficiency and user experience.\n",
            "\n",
            "Wait, I need to make sure the explanation is clear and in Korean. Also, check if there's any technical details I should include, like machine learning models or neural networks. Make sure the answer is concise but covers all aspects the user asked for.\n",
            "</think>\n",
            "\n",
            "6G ë„¤íŠ¸ì›Œí¬ì—ì„œ AIëŠ” ê¸°ìˆ ì  ê¸°ëŠ¥ê³¼ í˜‘ë ¥í•˜ì—¬ ìš°ì£¼í˜• í†µì‹  ê¸°ìˆ ì„ êµ¬í˜„í•˜ê³ , ì´ë¡ ì  ê¸°ëŒ€ì¹˜ë¥¼ í˜„ì‹¤í™”í•˜ê¸° ìœ„í•œ í•µì‹¬ ì—­í• ì„ í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì „ì—­ì  ê¸°ëŠ¥ì„ í†µí•´ ì´ë™í†µì‹ ê³¼ ì¸ê³µì§€ëŠ¥ì„ ê²°í•©í•˜ì—¬ ì°¨ì´ì ì´ ë¹›ë‚©ë‹ˆë‹¤.\n",
            "\n",
            "1. **ë‹¤ì–‘í•œ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„**: 6Gì€ ìˆ˜ì‹­ì–µ ëª…ì˜ ì‚¬ìš©ìì—ê²Œ ë°ì´í„°ë¥¼ ì†ì‰½ê²Œ ì œê³µí•˜ê¸° ìœ„í•œ AI ê¸°ë°˜ì˜ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ í†µí•©í•´, ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ë° ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
            "\n",
            "2. **ì£¼ì²´ì  ì¸í„°í˜ì´ìŠ¤ì™€ ì§€ì†ì  í˜‘ì—…**: AIë¥¼ í†µí•´ ì‚¬ìš©ìì˜ í–‰ë™ì„ ì´í•´í•˜ê³ , í†µì‹  ê²½í—˜ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì¸ê°„-AI í˜‘ì—…ì„ í†µí•´ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.\n",
            "\n",
            "3. **ì‹ ë¢°ì„±ê³¼ ì•ˆì •ì„± í–¥ìƒ**: AI ê¸°ë°˜ì˜ ê³ ê¸‰ ëª¨ë¸ë§ ë° ìë™í™” ê¸°ìˆ ì„ í†µí•´ í†µì‹  ì†ë„, ì‹ ë¢°ì„±, ì „ëµì  ì •ì±…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "4. **ì‹ ë¢°ì„± ìˆëŠ” ë°ì´í„° ì „ë‹¬**: AI ê¸°ë°˜ì˜ ë³´ì•ˆ ë° ë³´ì•ˆì„± ê¸°ìˆ ì€ 6Gì˜ ìœ„ì„±í˜• í†µì‹  ê¸°ëŠ¥ì„ ë”ìš± ì•ˆì „í•˜ê²Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
            "\n",
            "5. **ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ë¯¸ë˜ ê¸°ëŒ€ì¹˜**: AI ê¸°ë°˜ì˜ ï¿½\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from transformers import TextStreamer\n",
        "\n",
        "# 1. ì €ì¥ëœ ê²½ë¡œ ì„¤ì •\n",
        "save_dir = \"/content/drive/MyDrive/my_finetuned_qwen\"\n",
        "\n",
        "# 2. ëª¨ë¸ ë¡œë“œ\n",
        "print(f\"ğŸ“‚ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤: {save_dir}\")\n",
        "loaded_model, loaded_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = save_dir,\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "\n",
        "# 3. ì¶”ë¡  ëª¨ë“œ ì„¤ì •\n",
        "FastLanguageModel.for_inference(loaded_model)\n",
        "\n",
        "# 4. ì§ˆë¬¸ ì„¤ì • (í•œêµ­ì–´ ê°•ì œ í”„ë¡¬í”„íŠ¸ í¬í•¨)\n",
        "messages = [\n",
        "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: í•œêµ­ì–´ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ ë¶€ì—¬\n",
        "    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ 6G ì´ë™í†µì‹ ê³¼ AI ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"},\n",
        "\n",
        "    # ì‚¬ìš©ì ì§ˆë¬¸\n",
        "    {\"role\": \"user\", \"content\": \"6G ë„¤íŠ¸ì›Œí¬ì—ì„œ AIì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”? (í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜)\"}\n",
        "]\n",
        "\n",
        "# 5. í† í°í™” ë° ì‹¤í–‰\n",
        "inputs = loaded_tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "print(\"\\nğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\\n\")\n",
        "\n",
        "# 6. ë‹µë³€ ìƒì„±\n",
        "_ = loaded_model.generate(\n",
        "    input_ids=inputs,\n",
        "    streamer=TextStreamer(loaded_tokenizer, skip_prompt=True),\n",
        "    max_new_tokens=512,\n",
        "    use_cache=True,\n",
        "    temperature=0.7,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
